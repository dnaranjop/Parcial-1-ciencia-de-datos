{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informe sobre la Regresión Lineal con Gradiente Descendente en el Boston Housing Dataset\n",
    "\n",
    "**Nombre**: Damian Danilo Naranjo Perilla\n",
    "**Materia**: Ciencia de Datos  \n",
    "**Salón**: TS7A\n",
    "\n",
    "En este informe se implementa un modelo de regresión lineal simple usando el algoritmo de **gradiente descendente**. El dataset utilizado es el **Boston Housing**, y la variable independiente seleccionada es el número de habitaciones (`RM`) para predecir el valor medio de las viviendas (`MEDV`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar el dataset de Boston Housing desde openml\n",
    "boston = fetch_openml(name='boston', version=1, as_frame=True)\n",
    "\n",
    "# Datos de características (X) y objetivo (y)\n",
    "X = boston.data  # Variables independientes\n",
    "y = boston.target.values  # Convertir y a un array de numpy\n",
    "\n",
    "# Mostrar las primeras filas del dataset\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del Dataset\n",
    "\n",
    "El dataset de **Boston Housing** contiene información de precios de viviendas en varios suburbios de Boston. La característica principal que utilizamos en este análisis es el número promedio de habitaciones por vivienda (`RM`), y el objetivo es predecir el valor medio de las casas (`MEDV`), medido en miles de dólares.\n",
    "\n",
    "Este análisis se centra en la relación entre `RM` y `MEDV`, utilizando un modelo de regresión lineal simple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos la característica 'RM' (número de habitaciones) para la regresión\n",
    "X_rm = X['RM'].values.reshape(-1, 1)  # Reformateamos los datos para el modelo\n",
    "\n",
    "# Mostrar las primeras filas de RM\n",
    "X_rm[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de Gradiente Descendente\n",
    "\n",
    "El **gradiente descendente** es un algoritmo iterativo utilizado para minimizar la función de error de nuestro modelo, ajustando los parámetros de la pendiente (`m`) y el intercepto (`b`) de la recta de regresión. En cada iteración, el algoritmo ajusta estos parámetros para minimizar la diferencia entre los valores predichos y los reales.\n",
    "\n",
    "En este análisis:\n",
    "- Inicializamos los valores de la pendiente (`m = 0`) y el intercepto (`b = 0`).\n",
    "- Utilizamos una tasa de aprendizaje (`L = 0.01`).\n",
    "- Iteramos el proceso 1000 veces (`epochs = 1000`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización de parámetros\n",
    "m = 0  # Pendiente\n",
    "b = 0  # Intercepto\n",
    "L = 0.01  # Tasa de aprendizaje\n",
    "epochs = 1000  # Número de iteraciones\n",
    "\n",
    "n = float(len(X_rm))  # Número de datos\n",
    "\n",
    "# Implementación del algoritmo de gradiente descendente\n",
    "for i in range(epochs):\n",
    "    y_pred = m * X_rm + b  # Predicción actual\n",
    "    error = y - y_pred.flatten()  # Error actual, aplanar y_pred para que tenga la misma dimensión que y\n",
    "    D_m = (-2/n) * np.dot(X_rm.T, error)  # Derivada parcial con respecto a m\n",
    "    D_b = (-2/n) * np.sum(error)  # Derivada parcial con respecto a b\n",
    "    m = m - L * D_m  # Actualización de m\n",
    "    b = b - L * D_b  # Actualización de b\n",
    "\n",
    "# Predicción final con los parámetros ajustados\n",
    "y_pred = m * X_rm + b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "Después de 1000 iteraciones del algoritmo de gradiente descendente, se obtuvieron los parámetros óptimos para la pendiente (`m`) y el intercepto (`b`). Estos parámetros definen la línea de regresión que mejor ajusta los datos, prediciendo el valor medio de las casas en función del número de habitaciones.\n",
    "\n",
    "La ecuación de la regresión ajustada es:\n",
    "\\[\n",
    "\\hat{y} = m \\cdot RM + b\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la regresión lineal\n",
    "plt.scatter(X_rm, y, color='green')  # Gráfico de dispersión de los datos reales\n",
    "plt.plot(X_rm, y_pred, color='Black')  # Línea de regresión\n",
    "plt.xlabel('Número de habitaciones (RM)')\n",
    "plt.ylabel('Valor medio de las casas (MEDV)')\n",
    "plt.title('Regresión Lineal de Boston Housing')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "El modelo de regresión lineal ajustado muestra una relación positiva entre el número de habitaciones (`RM`) y el valor medio de las viviendas (`MEDV`). A medida que aumenta el número de habitaciones, también lo hace el valor medio de las casas.\n",
    "\n",
    "Este modelo es una simplificación, ya que solo utiliza una variable (`RM`), pero el dataset de Boston Housing contiene muchas otras características que podrían incorporarse para mejorar la precisión del modelo. Un análisis más completo incluiría variables como la ubicación, la tasa de criminalidad, entre otras, que también influyen en el valor de las viviendas.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
